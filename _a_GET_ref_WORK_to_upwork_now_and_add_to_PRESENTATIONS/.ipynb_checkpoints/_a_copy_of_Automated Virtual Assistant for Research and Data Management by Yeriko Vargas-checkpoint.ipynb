{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ad28c9",
   "metadata": {},
   "source": [
    "# Virtual Assistant for Research and Data Management by Yeriko Vargas\n",
    "\n",
    "## Summary\n",
    "This project utilizes Optical Character Recognition (OCR) technology to automate the process of extracting textual data from images, specifically from receipts. It closely aligns with the responsibilities of a Virtual Assistant by conducting extensive research through OCR, handling data management tasks, and merging data into a unified format for analysis.\n",
    "\n",
    "## Problem Addressed\n",
    "The project offers a solution to the problem of manually converting receipt images into a digital, machine-readable format. This capability could be extended to conduct comprehensive research by automating the extraction of valuable insights from various types of documents, which is one of the key responsibilities for the Virtual Assistant role.\n",
    "\n",
    "## How It Functions\n",
    "\n",
    "1. **Automated Research through Preprocessing**: The image undergoes preprocessing using OpenCV, simulating the Virtual Assistant's role in collecting relevant information. \n",
    "2. **Data Mining via Text Extraction**: The Tesseract OCR engine extracts textual data, which can be seen as a form of data mining, extracting valuable insights.\n",
    "3. **Data Management and Reporting**: The text is then processed and stored in a data frame, similar to how a Virtual Assistant would handle data management tasks in Microsoft Excel.\n",
    "\n",
    "## Diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b210569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                      Diagram\n",
    "\n",
    "#                +---------------------+\n",
    "#                |  Image Preprocessing|\n",
    "#                +---------------------+\n",
    "#                         |\n",
    "#                         V\n",
    "#                +---------------------+\n",
    "#                |   Text Extraction   |\n",
    "#                +---------------------+\n",
    "\n",
    "# Libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.adaptiveThreshold(cv2.GaussianBlur(img, (5, 5), 0), 255, \n",
    "                                cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    return img\n",
    "\n",
    "# Function to perform OCR\n",
    "def perform_ocr(img):\n",
    "    img_new = Image.open(img)\n",
    "    return pytesseract.image_to_string(img_new, lang='eng')\n",
    "\n",
    "# Main Function\n",
    "if __name__ == '__main__':\n",
    "    pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract/tesseract.exe'\n",
    "    \n",
    "    img = preprocess_image('rece.jpg')\n",
    "    cv2.imwrite('preprocessed_rece.jpg', img)\n",
    "\n",
    "    text = perform_ocr('preprocessed_rece.jpg')\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad09285",
   "metadata": {},
   "source": [
    "#  OCR_Receipt_Data_Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef445f7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Image Preprocessing: OpenCV is used to preprocess the receipt images, making them more suitable for OCR.\n",
    "Text Extraction: Tesseract OCR engine is used to extract text from the preprocessed images.\n",
    "Data Storage: The extracted text can be stored in a DataFrame or a text file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde127df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                           Diagram\n",
    "                              \n",
    "#                 +---------------------+\n",
    "#                 |  Image Preprocessing|\n",
    "#                 +---------------------+\n",
    "#                         |\n",
    "#                         V\n",
    "#                 +---------------------+\n",
    "#                 |   Text Extraction   |\n",
    "#                 +---------------------+\n",
    "#                         |\n",
    "#                         V\n",
    "#                 +---------------------+\n",
    "#                 |   Data Storage      |\n",
    "#                 +---------------------+\n",
    "\n",
    "# Libraries\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "    return img\n",
    "\n",
    "# Function to show image\n",
    "def show_image(img):\n",
    "    plt.figure(figsize=(12,16))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Function to perform OCR\n",
    "def perform_ocr(img):\n",
    "    return pytesseract.image_to_string(img, lang='eng')\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract/tesseract.exe'\n",
    "    \n",
    "    # Preprocess\n",
    "    img = preprocess_image('example.jpg')\n",
    "    \n",
    "    # Show preprocessed image\n",
    "    show_image(img)\n",
    "    \n",
    "    # Perform OCR\n",
    "    text = perform_ocr(img)\n",
    "    \n",
    "    # Display OCR result\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08db43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
