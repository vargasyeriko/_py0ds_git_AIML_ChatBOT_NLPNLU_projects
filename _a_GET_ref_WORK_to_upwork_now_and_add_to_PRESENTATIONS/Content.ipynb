{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42b8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;import io ; original_stdout = sys.stdout ; sys.stdout = io.StringIO()          # Suppress this output\n",
    "exec(open(f\"/Users/yerik/_apple_source/PY/GLOBAL/_1_paths.py\", encoding=\"utf-8\").read())  # GLOBAL\n",
    "direc = curr_direc ; sys.stdout = original_stdout                                         # Reset Suppress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68223809",
   "metadata": {},
   "source": [
    "# FROM Jupyter notebook -> PDF -> pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b2282",
   "metadata": {},
   "source": [
    "## general info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd85b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name =  'DL_AI_Classify_Sentences_NLP_Presentation'\n",
    "\n",
    "\n",
    "title_pdf = 'New title'\n",
    "pdf_desc = 'DL_AI_Classify_Sentences_NLP_Presentation'\n",
    "tools = [\"Sentence Tokenization\", \"Stop Word Filtering\", \"Lemmatization\", \"Data Preprocessing\", \"Neural Network Modeling\", \"Accuracy Evaluation\"]\n",
    "hashtags = [\"DataScience\", \"ArtificialIntelligence\", \"MachineLearning\", \"NaturalLanguageProcessing\", \"DeepLearning\", \"Python\", \"DataAnalytics\", \"NeuralNetworks\"]\n",
    "\n",
    "cai_foot = 'CAI -> www.customaimodels.com'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert import NotebookExporter\n",
    "import nbformat\n",
    "\n",
    "# Initialize NotebookExporter\n",
    "exporter = NotebookExporter()\n",
    "\n",
    "# The name of your notebook file\n",
    "notebook_file = 'upwork.ipynb'\n",
    "\n",
    "# The name of the output file\n",
    "output_file = 'exported_notebook2.ipynb'\n",
    "\n",
    "# Read the notebook using nbformat\n",
    "notebook_content = nbformat.read(notebook_file, as_version=4)\n",
    "\n",
    "# Export the notebook into a different format\n",
    "exported_content, resources = exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Write the exported content to a file\n",
    "with open(output_file, 'wb') as f:\n",
    "    f.write(exported_content.encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00033d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert import PDFExporter\n",
    "pdf_exporter = PDFExporter()\n",
    "pdf_data, resources = pdf_exporter.from_filename(\"upwork.ipynb\")\n",
    "with open(\"YourNotebook.pdf\", \"wb\") as f:\n",
    "    f.write(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef50821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2350f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e70c9fe",
   "metadata": {},
   "source": [
    "# From PDF to PICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "215a8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from PyPDF2 import PdfReader\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Function to convert PDF to a list of images\n",
    "def pdf_to_images(pdf_path, image_path_prefix):\n",
    "    \"\"\"\n",
    "    Convert PDF to a set of images.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_path: Path to the PDF file\n",
    "    - image_path_prefix: Prefix for the generated image files\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize PDF Reader\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    \n",
    "    # Get the number of pages\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    # Convert each page to image\n",
    "    images = convert_from_path(pdf_path)\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f\"{image_path_prefix}_{i+1}.png\", 'PNG')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    pdf_to_images(f'{pdf_name}.pdf', f'{desk_path}/content_now/output_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749c960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5a980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea732a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb48a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1afb1db7",
   "metadata": {},
   "source": [
    "# Captions and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d84a02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Define function to encode text for URLs\n",
    "def url_encode(text):\n",
    "    return quote(text)\n",
    "\n",
    "# Define a function to create LinkedIn captions\n",
    "def generate_caption(title, author, description, tools_techniques, hashtags):\n",
    "    \"\"\"\n",
    "    Generate a LinkedIn post caption.\n",
    "    \n",
    "    Parameters:\n",
    "    - title (str): The title of your content or project\n",
    "    - author (str): Your name\n",
    "    - description (str): Brief description of your content\n",
    "    - tools_techniques (list): A list of tools or techniques used\n",
    "    - hashtags (list): A list of hashtags to include\n",
    "    \n",
    "    Returns:\n",
    "    - str: The complete caption\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the header section\n",
    "    header = f\"üîç \\\"{title}\\\" by {author}\\n\"\n",
    "    \n",
    "    # Create the description section\n",
    "    description_section = f\"{description}\\n\\n\"\n",
    "    \n",
    "    # Create the Tools & Techniques section\n",
    "    tools_section = \"üõ†Ô∏è Tools & Techniques:\\n\"\n",
    "    for tool in tools_techniques:\n",
    "        tools_section += f\"- {tool} üåü\\n\"\n",
    "    \n",
    "    # Create the hashtag section\n",
    "    hashtags_section = \" \".join([f\"#{tag}\" for tag in hashtags])\n",
    "    \n",
    "    # Combine all sections\n",
    "    full_caption = f\"{header}{description_section}{tools_section}\\n{hashtags_section}\"\n",
    "    \n",
    "    return full_caption\n",
    "\n",
    "# Define a function to generate social media links\n",
    "def generate_social_links(name, platform):\n",
    "    \"\"\"\n",
    "    Generate social media links for Yeriko and CAI\n",
    "    \n",
    "    Parameters:\n",
    "    - name (str): The name (either \"Yeriko\" or \"CAI\")\n",
    "    - platform (str): The social media platform (\"twitter\", \"instagram\", \"linkedin\")\n",
    "    \n",
    "    Returns:\n",
    "    - str: The social media link\n",
    "    \"\"\"\n",
    "    base_urls = {\n",
    "        \"twitter\": \"https://twitter.com/\",\n",
    "        \"instagram\": \"https://instagram.com/\",\n",
    "        \"linkedin\": \"https://linkedin.com/in/\"\n",
    "    }\n",
    "    \n",
    "    usernames = {\n",
    "        \"Yeriko\": \"yeriko_username\",\n",
    "        \"CAI\": \"cai_username\"\n",
    "    }\n",
    "    \n",
    "    url = f\"{base_urls[platform]}{url_encode(usernames[name])}\"\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8286f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç \"New title\" by Yeriko Vargas\n",
      "DL_AI_Classify_Sentences_NLP_Presentation\n",
      "\n",
      "üõ†Ô∏è Tools & Techniques:\n",
      "- Sentence Tokenization üåü\n",
      "- Stop Word Filtering üåü\n",
      "- Lemmatization üåü\n",
      "- Data Preprocessing üåü\n",
      "- Neural Network Modeling üåü\n",
      "- Accuracy Evaluation üåü\n",
      "\n",
      "#DataScience #ArtificialIntelligence #MachineLearning #NaturalLanguageProcessing #DeepLearning #Python #DataAnalytics #NeuralNetworks\n",
      "\n",
      "Yeriko's Social Media:\n",
      "Twitter: https://twitter.com/yeriko_username\n",
      "Instagram: https://instagram.com/yeriko_username\n",
      "Linkedin: https://linkedin.com/in/yeriko_username\n",
      "\n",
      "CAI's Social Media:\n",
      "Twitter: https://twitter.com/cai_username\n",
      "Instagram: https://instagram.com/cai_username\n",
      "Linkedin: https://linkedin.com/in/cai_username\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    title = title_pdf  # Replace with your PDF title\n",
    "    author = \"Yeriko Vargas\"\n",
    "    description = pdf_desc  # Replace with your PDF description\n",
    "    tools_techniques = tools  # Replace with your tools and techniques\n",
    "    hashtags = hashtags  # Replace with your hashtags\n",
    "    caption = generate_caption(title, author, description, tools_techniques, hashtags)\n",
    "    \n",
    "    yeriko_social_links = \"\\n\".join([f\"{platform.capitalize()}: {generate_social_links('Yeriko', platform)}\"\n",
    "                                     for platform in [\"twitter\", \"instagram\", \"linkedin\"]])\n",
    "                                     \n",
    "    cai_social_links = \"\\n\".join([f\"{platform.capitalize()}: {generate_social_links('CAI', platform)}\"\n",
    "                                  for platform in [\"twitter\", \"instagram\", \"linkedin\"]])\n",
    "\n",
    "    final_caption = f\"{caption}\\n\\nYeriko's Social Media:\\n{yeriko_social_links}\\n\\nCAI's Social Media:\\n{cai_social_links}\"\n",
    "    \n",
    "    # The `final_caption` variable contains the entire LinkedIn caption along with social media links\n",
    "    print(final_caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319ed5d",
   "metadata": {},
   "source": [
    "# copy caption to clipboard automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f2ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "# Copying to clipboard\n",
    "pyperclip.copy(final_caption)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47646538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270cd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4374d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271c193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25d29add",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'üîç' (U+1F50D) (3450409686.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    üîç \"New title\" by Yeriko Vargas\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character 'üîç' (U+1F50D)\n"
     ]
    }
   ],
   "source": [
    "üîç \"New title\" by Yeriko Vargas\n",
    "DL_AI_Classify_Sentences_NLP_Presentation\n",
    "\n",
    "üõ†Ô∏è Tools & Techniques:\n",
    "- Sentence Tokenization üåü\n",
    "- Stop Word Filtering üåü\n",
    "- Lemmatization üåü\n",
    "- Data Preprocessing üåü\n",
    "- Neural Network Modeling üåü\n",
    "- Accuracy Evaluation üåü\n",
    "\n",
    "#DataScience #ArtificialIntelligence #MachineLearning #NaturalLanguageProcessing #DeepLearning #Python #DataAnalytics #NeuralNetworks\n",
    "\n",
    "Yeriko's Social Media:\n",
    "Twitter: https://twitter.com/yeriko_username\n",
    "Instagram: https://instagram.com/yeriko_username\n",
    "Linkedin: https://linkedin.com/in/yeriko_username\n",
    "\n",
    "CAI's Social Media:\n",
    "Twitter: https://twitter.com/cai_username\n",
    "Instagram: https://instagram.com/cai_username\n",
    "Linkedin: https://linkedin.com/in/cai_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd5062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
