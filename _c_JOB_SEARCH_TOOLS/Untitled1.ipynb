{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5e5e062-debb-4183-affe-0dd6106e8454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all= pd.read_pickle('ds_jobs.pkl')\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ecf1aef-48ae-4de3-b3ee-40c65ca901b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have a DataFrame named 'df' and a categorical variable named 'category_column'\n",
    "df_all['Identifier'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbcf2a43-5078-401b-82bc-6f5ef9531d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_dfs(df_8, df_all, \"ds_jobs.pkl\")\n",
    "\n",
    "df_all= pd.read_pickle('ds_jobs.pkl')\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5961c30a-70e0-4019-8f6e-2791770f3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for the newly provided professional experience\n",
    "data_new_7 = {\n",
    "    \"Identifier\": [\"FORD\", \"FORD\", \"FORD\", \"FORD\", \"SA\", \"SA\", \"SA\", \"SA\", \"FCA\", \"FCA\", \"FCA\", \"FCA\"],\n",
    "    \"Role & Company\": [\n",
    "        \"Lead Data Scientist, Ford\", \"Lead Data Scientist, Ford\", \"Lead Data Scientist, Ford\", \"Lead Data Scientist, Ford\",\n",
    "        \"Machine Learning Researcher, Soothsayer Analytics\", \"Machine Learning Researcher, Soothsayer Analytics\",\n",
    "        \"Machine Learning Researcher, Soothsayer Analytics\", \"Machine Learning Researcher, Soothsayer Analytics\",\n",
    "        \"Deep Learning Specialist, Fiat Chrysler Automotive\", \"Deep Learning Specialist, Fiat Chrysler Automotive\",\n",
    "        \"Deep Learning Specialist, Fiat Chrysler Automotive\", \"Deep Learning Specialist, Fiat Chrysler Automotive\"\n",
    "    ],\n",
    "    \"Action Verb\": [\n",
    "        \"Managed, Manipulated & Analyzed\", \"Acted, Transformed & Visualized\", \"Collaborated, Built & Solved\", \"Automatized & Transferred\",\n",
    "        \"Researched & Utilized\", \"Performed, Mined & Plotted\", \"Used, Visualized & Modified\", \"Found & Visualized\",\n",
    "        \"Assembled & Forecasted\", \"Constructed & Tested\", \"Built & Optimized\", \"Applied & Solved\"\n",
    "    ],\n",
    "    \"Task/Content\": [\n",
    "        \"Managed big data from CVDOS database to meet internal client data requirements using Python.\",\n",
    "        \"Transformed, merged, and visualized data sets using Python, AWS SageMaker, and Jupyter notebooks.\",\n",
    "        \"Collaborated with engineers and project managers to address car defects using Machine Learning.\",\n",
    "        \"Automated process for transferring live data and statistics to internal customers using Python, SQL, and Hadoop.\",\n",
    "        \"Researched ML methods for fraud detection, customer segmentation, and service automation.\",\n",
    "        \"Performed data mining to preprocess ML model outputs and identify fraudulent shops using Plotly and Sklearn.\",\n",
    "        \"Used SHAP in Python to adjust ML models for predicting customer dissatisfaction through Random Forest models.\",\n",
    "        \"Analyzed service shop data to detect fraudulent activities among 500 locations using ML methods and visualization tools.\",\n",
    "        \"Developed Deep Learning models using R-Keras and Python packages to forecast profitable configurations.\",\n",
    "        \"Tested various AI models to evaluate metrics like accuracy, layer count, loss function, optimizer, epochs, and batch sizes.\",\n",
    "        \"Optimized production to classify car models and body-parts using a quarter-million data set.\",\n",
    "        \"Applied Neural Network methods for automotive storage optimization, impacting car sales configurations and storage solutions.\"\n",
    "    ],\n",
    "    \"Results\": [\n",
    "        \"Enhanced internal data analysis and reporting.\", \n",
    "        \"Streamlined data visualization and reporting for daily updates.\",\n",
    "        \"Implemented ML solutions for recurring car defects.\",\n",
    "        \"Reduced human error in data transfer processes.\",\n",
    "        \"Identified effective ML methodologies for diverse applications.\",\n",
    "        \"Enhanced fraud detection capabilities in customer service.\",\n",
    "        \"Improved accuracy in customer dissatisfaction predictions.\",\n",
    "        \"Identified fraudulent activities across multiple locations.\",\n",
    "        \"Forecasted profitable car configurations effectively.\",\n",
    "        \"Refined AI model performance and accuracy.\",\n",
    "        \"Adjusted car production leading to increased efficiency.\",\n",
    "        \"Solved significant automotive storage optimization issues.\"\n",
    "    ],\n",
    "    \"Method/How You Did It\": [\n",
    "        \"Utilized Python for data manipulation and analysis.\",\n",
    "        \"Employed Python, AWS SageMaker, and Jupyter for data transformation.\",\n",
    "        \"Applied Cluster Analysis and PCA methodology in Machine Learning.\",\n",
    "        \"Implemented Python, SQL, and Hadoop for automation.\",\n",
    "        \"Explored various Machine Learning techniques and functions.\",\n",
    "        \"Used Plotly, Sklearn, and Python for data mining and visualization.\",\n",
    "        \"Applied SHAP package and Random Forest models in Python.\",\n",
    "        \"Employed Tableau, matplotlib, ggplot2, Power BI for anomaly visualization.\",\n",
    "        \"Developed models using R-Keras and Python packages like pandas, Sklearn.\",\n",
    "        \"Tested AI models with different configurations and metrics.\",\n",
    "        \"Analyzed data to optimize production and configuration classifications.\",\n",
    "        \"Implemented Neural Networks for storage optimization and sales analysis.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_8 = pd.DataFrame(data_new_7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ba999-4d13-4c93-a3bd-2242115ae154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c08049-69d3-4909-a93e-aa860dbe5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def stack_dfs(initial_df, new_df, file_path):\n",
    "    \"\"\"\n",
    "    Stacks a new DataFrame on top of an existing one, saves the combined DataFrame,\n",
    "    and then reads it back.\n",
    "\n",
    "    :param initial_df: The initial DataFrame or None if starting fresh.\n",
    "    :param new_df: The new DataFrame to add.\n",
    "    :param file_path: Path of the .pkl file to read/write.\n",
    "    :return: The combined DataFrame after stacking and re-reading.\n",
    "    \"\"\"\n",
    "\n",
    "    # If initial_df is None, start with the new DataFrame\n",
    "    if initial_df is None:\n",
    "        combined_df = new_df\n",
    "    else:\n",
    "        # Stack the new DataFrame onto the initial one\n",
    "        combined_df = pd.concat([initial_df, new_df], ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a .pkl file\n",
    "    combined_df.to_pickle(file_path)\n",
    "\n",
    "    # Read the .pkl file back into a DataFrame\n",
    "    stacked_df = pd.read_pickle(file_path)\n",
    "\n",
    "    return stacked_df\n",
    "\n",
    "# # Example usage\n",
    "# file_path = 'stacked_data.pkl'  # Define the file path\n",
    "\n",
    "# # Assuming df1 and df2 are existing DataFrames you want to stack and save\n",
    "# # You can replace these with your actual DataFrames\n",
    "# df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "# df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "# # First time, pass None as the initial DataFrame\n",
    "# stacked_df = stack_and_save_dfs(None, df1, file_path)\n",
    "\n",
    "# # Next, pass the stacked DataFrame and the new DataFrame\n",
    "# stacked_df = stack_and_save_dfs(stacked_df, df2, file_path)\n",
    "\n",
    "# # The stacked_df now contains the combined data from df1 and df2\n",
    "# print(stacked_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ed70a-954e-442d-a755-fb6f155fcb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
